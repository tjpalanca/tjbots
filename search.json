[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TJBots",
    "section": "",
    "text": "To explore the jagged frontier of the capabilities of LLMs, I think the right approach is to be very experimental - try out new use cases and see how we can tweak the various levers (prompts, models, tools, configurations) to solve the goal.\nIn order to do that, I think we need to build a test harness for trying out various configurations against different problems, for the following purposes:\n\nto reduce the time from an idea (hey, maybe I can use an LLM to solve it) to implementing it in code where I can hold it and use it in my day-to-day life, and\nif there are problems that are currently unsolvable, be able to take advantage of new research and tools developed to re-visit them in the future.\nmake it easy for me to share my findings with others, so that they can benefit from my work and I can learn from them."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "TJBots",
    "section": "",
    "text": "To explore the jagged frontier of the capabilities of LLMs, I think the right approach is to be very experimental - try out new use cases and see how we can tweak the various levers (prompts, models, tools, configurations) to solve the goal.\nIn order to do that, I think we need to build a test harness for trying out various configurations against different problems, for the following purposes:\n\nto reduce the time from an idea (hey, maybe I can use an LLM to solve it) to implementing it in code where I can hold it and use it in my day-to-day life, and\nif there are problems that are currently unsolvable, be able to take advantage of new research and tools developed to re-visit them in the future.\nmake it easy for me to share my findings with others, so that they can benefit from my work and I can learn from them."
  },
  {
    "objectID": "notes/01-development/index.html",
    "href": "notes/01-development/index.html",
    "title": "Development",
    "section": "",
    "text": "Development\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "notes/02-bots/03-reconnection.html",
    "href": "notes/02-bots/03-reconnection.html",
    "title": "Reconnection Behavior",
    "section": "",
    "text": "The current setup is now that we use a dockerised Shiny Server Pro instance to serve the app at the root directory. This enables reconnection behavior at the server side where sessions are held for up to 15 seconds (customisable but only at source code level), and reconnect once it’s established.\nWhen the connection is reestablished, the last chat message is reinitialized. The bot sends another message when it had already been sent. In addition, the chat client does not receive the old messages that were sent prior to the disconnection.",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Reconnection Behavior"
    ]
  },
  {
    "objectID": "notes/02-bots/03-reconnection.html#determining-the-status-of-chat-messages",
    "href": "notes/02-bots/03-reconnection.html#determining-the-status-of-chat-messages",
    "title": "Reconnection Behavior",
    "section": "Determining the status of chat messages",
    "text": "Determining the status of chat messages\nWe first want to find out what chat messages look like in the frontend and in the backend.\n\nfrom dotenv import load_dotenv\nfrom chatlas import ChatAnthropic\nfrom datetime import datetime\n\nload_dotenv(\"/run/secrets/tjbots.env\")\n\nchat = ChatAnthropic()\n\n\ndef get_current_time():\n    return datetime.now().isoformat()\n\n\nchat.register_tool(get_current_time)\nchat.chat(\"Can you fetch the current time\")\n\n\ndir(chat.get_turns()[1])\n\n\nimport chatlas\n\nchatlas.Turn",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Reconnection Behavior"
    ]
  },
  {
    "objectID": "notes/02-bots/01-pwa.html",
    "href": "notes/02-bots/01-pwa.html",
    "title": "Progressive Web App",
    "section": "",
    "text": "Enable this by creating a manifest.json and linking to it with a &lt;link rel=\"manifest\"&gt; tag.\nAdd to home screen on iOS works, but the icon is not displayed.\n\nWe needed to add the apple-touch-icon link to a PNG file, as it does not accept SVG files.\n\nThe interface should not be pinch-to-zoomable when added to the home screen.\n\nAdd this meta tag to disable pinch to zoom so it doesn’t create problems with the theme.\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no, viewport-fit=cover\"/&gt;\nDisabling overscroll worked\nhtml {\n    overscroll-behavior: none;\n}\n\nbody {\n    overflow-y: scroll;\n}\n\nThe sidebar should display during swipe events.\n\nI think this requires some custom mobile framework like Framework7 and would likely be an overoptimisation if ever.\n\n\n\n\n\n\nDocs\n\n\n\nDocs",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Progressive Web App"
    ]
  },
  {
    "objectID": "notes/02-bots/01-pwa.html#enhancements",
    "href": "notes/02-bots/01-pwa.html#enhancements",
    "title": "Progressive Web App",
    "section": "",
    "text": "Docs\n\n\n\nDocs",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Progressive Web App"
    ]
  },
  {
    "objectID": "notes/02-bots/02-deployment.html",
    "href": "notes/02-bots/02-deployment.html",
    "title": "Deployment",
    "section": "",
    "text": "Use the docker-in-docker devcontainer feature to quickly add the ability to build images without allowing access to your own machine’s docker host.\nUse uvicorn as the main docker command. There’s another configuration using gunicorn but some cursory research made that overkill for just docker runs.\nCMD [\"uv\", \"run\", \"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\nCan we build off of the production dev container to build the dev image by adding more stuff onto it?\n\nI think the best way is to still construct a slimmed down version. We can get consistency by making sure we both have the same base image, which as of writing was python-3.12-bookworm.\nThis general pattern allows us to consolidate configuration in the pyproject.toml file. It only requires python.\nVERSION := $(shell python -c 'import tomllib; print(tomllib.load(open(\"pyproject.toml\", \"rb\"))[\"project\"][\"version\"])')\n\nThe base images all run as root, it’s best to run as a non-root user:\n# Downgrade to non-root user \nRUN useradd -u 1000 -m appuser\nUSER appuser\nI needed to generate both arm64 and amd64 versions for the application images. Currently in runs on my HomeLab (M1 Mac Mini), but it might run in the cloud in the future.\n\nOne strategy I tried was to cycle through two different runners as a strategy, but the arm64 ubuntu runner did not have Python.\n\nUse a registry cache to speed up docker builds. Add these arguments to the docker build command. A complete cache hit (re-run) went from 51s to 31s.\napp-push:\n    docker buildx build \\\n        $(APP_BUILD_ARGS) \\\n        --cache-to=type=registry,ref=$(APP_IMG):cache,mode=max \\\n        --cache-from=type=registry,ref=$(APP_IMG):cache \\\n        --push . \n\n\n\n\n\nWe can use watchtower as a lightweight way of updating the docker images as soon as they are updated in the registry.\n\nThis also supports docker compose.\nWorked well. We just needed to specify the container_name in the compose.yml to have consistent container names, then set the interval to be shorter (from the default 24 horus) to facilitate frequent updates.\n\nservices:\n    watchtower:\n        image: containrrr/watchtower:latest\n        container_name: watchtower\n        restart: always\n        volumes:\n        - /var/run/docker.sock:/var/run/docker.sock\n        command: tjbots-app --interval 30 --cleanup\nI think we can initially start with just running the bare container and then we can start using something like shinyproxy if we feel the need to scale.\n\n\n\n\n\nAfter the PWA has been open for quite some time, it will gray out. At a minimum we should start a fresh session, but at best we should reconnect to the existing session as if nothing has happened.\n\nSome things we can try:\n\nPosit Connect Cloud\n\nI tried it just to see if I can get the right reconnection behavior - it works.\nI know that Shiny Server products will work then.\nI don’t want to use this as it doesn’t offer custom domains and does not allow me to place authentication on top of the application.\n\nShiny Server Open Source\n\nit seems that it has the needed reconnect behavior.\nthere are no pre-build arm64 binaries. I’m going to need to build from source\nI remembered a problem I struggled with before - Shiny Server Open Source does not pass along necessary headers. This isn’t a problem now, but is going to be a problem should I decide to do Auth0 authentication. There is a hack to modify this behavior.\n\nThe repo and package for this modified shiny server and for arm64 is at tjpalanca/shiny-server.\n\nFor now I’ll move on first to ShinyProxy as it has a more complete feature set and I can always come back to this later.\nI eventually gave this a try, but it was not a good experience.\n\nI had to build from source due to the lack of pre-built ARM binaries.\nI had to change the source code to enable headers to be passed through.\nThe reconnection behavior wasn’t seamless, it would reinitialize the inputs.\n\nPR for enabling reconnections in rstudio/shiny-server\nI went through it anyway and decided to incorporate the changes in my application. The benefits are:\n\nSockJS will fall back to another protocol if websockets is not supported.\nGraceful resumption still happens for network switching, which is going to alleviate cases when user does not intend to disconnect (did not close the app).\nSome element of scalability through the scheduler.\n\nWe need to manually whitelist the headers that would be passed through to the websocket creation request, but this is alright.\nWhat’s unsolved:\n\nResuming after a long disconnection, likely to be solved via server-side caching of state.\n\n\nShinyProxy\n\nI can’t find indications that it has reconnect behavior; given that it can run all sorts of other dockerized applications, it might expect the application to handle that.\nI tried this, and their operator implementation was very smooth. It was very easy to setup on a plain Docker host and I like that they have a Kubernetes operator.\nI did eventually find the reconnection setting.\n\nIt re-sent the inputs, so the @chatui.on_user_submit callback was called again, creating a duplicate response. Additionally, since the server state was reset, the chat history was not on the chatlas object.\nThe reconnection behavior only worked when it was on the /app endpoint which contained some shinyproxy wrapper code, but that interfered with the PWA capabilities.\n\nI can still try to use this as a way to run the application, but I will need to understand how to serve at root path and re-enable the PWA capabilities.\nI have a few options to try:\n\nAdd another layer that rewrites the URL to /app and serves the PWA.\n\nA problem here is that even manifest.json files served at /app have the iframes\nMight need to use the /app_direct endpoint for the manifest itself.\nChatGPT says having the manifest in a different path should work, only cross-origin has complications.\n\n\nI’m encountering a bug where shinyproxy instance is unable to communicate with the docker daemon after some point in time.\nI decided that while this will probably be very nice for creating devcontainers, it’s overkill for just a single app instance.\nIt turns out there is no way to enable reconnecting behavior from Python although it still works well. We just added a script that flips that to true on the client side when shiny is connected.\nui.tags.script(\"\"\"\n$(document).on('shiny:connected', function() {\n    if (window.Shiny && Shiny.shinyapp) Shiny.shinyapp.$allowReconnect = true;\n});\n\"\"\")",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Deployment"
    ]
  },
  {
    "objectID": "notes/02-bots/02-deployment.html#creating-a-deployable-docker-container",
    "href": "notes/02-bots/02-deployment.html#creating-a-deployable-docker-container",
    "title": "Deployment",
    "section": "",
    "text": "Use the docker-in-docker devcontainer feature to quickly add the ability to build images without allowing access to your own machine’s docker host.\nUse uvicorn as the main docker command. There’s another configuration using gunicorn but some cursory research made that overkill for just docker runs.\nCMD [\"uv\", \"run\", \"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\nCan we build off of the production dev container to build the dev image by adding more stuff onto it?\n\nI think the best way is to still construct a slimmed down version. We can get consistency by making sure we both have the same base image, which as of writing was python-3.12-bookworm.\nThis general pattern allows us to consolidate configuration in the pyproject.toml file. It only requires python.\nVERSION := $(shell python -c 'import tomllib; print(tomllib.load(open(\"pyproject.toml\", \"rb\"))[\"project\"][\"version\"])')\n\nThe base images all run as root, it’s best to run as a non-root user:\n# Downgrade to non-root user \nRUN useradd -u 1000 -m appuser\nUSER appuser\nI needed to generate both arm64 and amd64 versions for the application images. Currently in runs on my HomeLab (M1 Mac Mini), but it might run in the cloud in the future.\n\nOne strategy I tried was to cycle through two different runners as a strategy, but the arm64 ubuntu runner did not have Python.\n\nUse a registry cache to speed up docker builds. Add these arguments to the docker build command. A complete cache hit (re-run) went from 51s to 31s.\napp-push:\n    docker buildx build \\\n        $(APP_BUILD_ARGS) \\\n        --cache-to=type=registry,ref=$(APP_IMG):cache,mode=max \\\n        --cache-from=type=registry,ref=$(APP_IMG):cache \\\n        --push .",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Deployment"
    ]
  },
  {
    "objectID": "notes/02-bots/02-deployment.html#deploying-the-docker-container",
    "href": "notes/02-bots/02-deployment.html#deploying-the-docker-container",
    "title": "Deployment",
    "section": "",
    "text": "We can use watchtower as a lightweight way of updating the docker images as soon as they are updated in the registry.\n\nThis also supports docker compose.\nWorked well. We just needed to specify the container_name in the compose.yml to have consistent container names, then set the interval to be shorter (from the default 24 horus) to facilitate frequent updates.\n\nservices:\n    watchtower:\n        image: containrrr/watchtower:latest\n        container_name: watchtower\n        restart: always\n        volumes:\n        - /var/run/docker.sock:/var/run/docker.sock\n        command: tjbots-app --interval 30 --cleanup\nI think we can initially start with just running the bare container and then we can start using something like shinyproxy if we feel the need to scale.",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Deployment"
    ]
  },
  {
    "objectID": "notes/02-bots/02-deployment.html#solving-reconnection-issues",
    "href": "notes/02-bots/02-deployment.html#solving-reconnection-issues",
    "title": "Deployment",
    "section": "",
    "text": "After the PWA has been open for quite some time, it will gray out. At a minimum we should start a fresh session, but at best we should reconnect to the existing session as if nothing has happened.\n\nSome things we can try:\n\nPosit Connect Cloud\n\nI tried it just to see if I can get the right reconnection behavior - it works.\nI know that Shiny Server products will work then.\nI don’t want to use this as it doesn’t offer custom domains and does not allow me to place authentication on top of the application.\n\nShiny Server Open Source\n\nit seems that it has the needed reconnect behavior.\nthere are no pre-build arm64 binaries. I’m going to need to build from source\nI remembered a problem I struggled with before - Shiny Server Open Source does not pass along necessary headers. This isn’t a problem now, but is going to be a problem should I decide to do Auth0 authentication. There is a hack to modify this behavior.\n\nThe repo and package for this modified shiny server and for arm64 is at tjpalanca/shiny-server.\n\nFor now I’ll move on first to ShinyProxy as it has a more complete feature set and I can always come back to this later.\nI eventually gave this a try, but it was not a good experience.\n\nI had to build from source due to the lack of pre-built ARM binaries.\nI had to change the source code to enable headers to be passed through.\nThe reconnection behavior wasn’t seamless, it would reinitialize the inputs.\n\nPR for enabling reconnections in rstudio/shiny-server\nI went through it anyway and decided to incorporate the changes in my application. The benefits are:\n\nSockJS will fall back to another protocol if websockets is not supported.\nGraceful resumption still happens for network switching, which is going to alleviate cases when user does not intend to disconnect (did not close the app).\nSome element of scalability through the scheduler.\n\nWe need to manually whitelist the headers that would be passed through to the websocket creation request, but this is alright.\nWhat’s unsolved:\n\nResuming after a long disconnection, likely to be solved via server-side caching of state.\n\n\nShinyProxy\n\nI can’t find indications that it has reconnect behavior; given that it can run all sorts of other dockerized applications, it might expect the application to handle that.\nI tried this, and their operator implementation was very smooth. It was very easy to setup on a plain Docker host and I like that they have a Kubernetes operator.\nI did eventually find the reconnection setting.\n\nIt re-sent the inputs, so the @chatui.on_user_submit callback was called again, creating a duplicate response. Additionally, since the server state was reset, the chat history was not on the chatlas object.\nThe reconnection behavior only worked when it was on the /app endpoint which contained some shinyproxy wrapper code, but that interfered with the PWA capabilities.\n\nI can still try to use this as a way to run the application, but I will need to understand how to serve at root path and re-enable the PWA capabilities.\nI have a few options to try:\n\nAdd another layer that rewrites the URL to /app and serves the PWA.\n\nA problem here is that even manifest.json files served at /app have the iframes\nMight need to use the /app_direct endpoint for the manifest itself.\nChatGPT says having the manifest in a different path should work, only cross-origin has complications.\n\n\nI’m encountering a bug where shinyproxy instance is unable to communicate with the docker daemon after some point in time.\nI decided that while this will probably be very nice for creating devcontainers, it’s overkill for just a single app instance.\nIt turns out there is no way to enable reconnecting behavior from Python although it still works well. We just added a script that flips that to true on the client side when shiny is connected.\nui.tags.script(\"\"\"\n$(document).on('shiny:connected', function() {\n    if (window.Shiny && Shiny.shinyapp) Shiny.shinyapp.$allowReconnect = true;\n});\n\"\"\")",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground",
      "Deployment"
    ]
  },
  {
    "objectID": "notes/02-bots/index.html",
    "href": "notes/02-bots/index.html",
    "title": "Bots Playground",
    "section": "",
    "text": "I want to create a test harness that allows me to quickly test our various levers, including:\n\nLLM model providers (e.g. OpenAI, Anthropic, Google) and models (e.g. GPT-4, Claude 3, Gemini)\nSystem and user prompts\nTools (e.g. web search, code execution, memory, etc.)\nConfiguration (e.g. chain-of-thought)\n\nThe sources of these configurations can come from:\n\nproblems I want to solve\narticles I read about LLMs that give me ideas\n\n\n\n\nMost providers will not be model agnostic, they will only support one provider, especially in relation to these open-weight models.\nMost providers will charge a margin over the raw API cost.\nWe cannot experiment with human-AI interfaces because the interfaces are fixed.\nIt’s harder to compose more complex model configurations and to add tools via MCP servers creates additional overhead.\n\n\n\n\n\n\n\n\nMobile first\n\n\n\n\n\n\n\n\nOnly add complexity when necessary but don’t create one-way doors.\nMinimise drift between development and production as much as possible.",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground"
    ]
  },
  {
    "objectID": "notes/02-bots/index.html#motivation",
    "href": "notes/02-bots/index.html#motivation",
    "title": "Bots Playground",
    "section": "",
    "text": "I want to create a test harness that allows me to quickly test our various levers, including:\n\nLLM model providers (e.g. OpenAI, Anthropic, Google) and models (e.g. GPT-4, Claude 3, Gemini)\nSystem and user prompts\nTools (e.g. web search, code execution, memory, etc.)\nConfiguration (e.g. chain-of-thought)\n\nThe sources of these configurations can come from:\n\nproblems I want to solve\narticles I read about LLMs that give me ideas\n\n\n\n\nMost providers will not be model agnostic, they will only support one provider, especially in relation to these open-weight models.\nMost providers will charge a margin over the raw API cost.\nWe cannot experiment with human-AI interfaces because the interfaces are fixed.\nIt’s harder to compose more complex model configurations and to add tools via MCP servers creates additional overhead.",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground"
    ]
  },
  {
    "objectID": "notes/02-bots/index.html#design",
    "href": "notes/02-bots/index.html#design",
    "title": "Bots Playground",
    "section": "",
    "text": "Mobile first",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground"
    ]
  },
  {
    "objectID": "notes/02-bots/index.html#deployment",
    "href": "notes/02-bots/index.html#deployment",
    "title": "Bots Playground",
    "section": "",
    "text": "Only add complexity when necessary but don’t create one-way doors.\nMinimise drift between development and production as much as possible.",
    "crumbs": [
      "Home",
      "Notes",
      "Bots Playground"
    ]
  },
  {
    "objectID": "notes/01-development/01-devcontainer.html",
    "href": "notes/01-development/01-devcontainer.html",
    "title": "Dev Container",
    "section": "",
    "text": "Used microsoft’s base dev container and some devcontainer features to enable python with uv, nodejs, and quarto. This creates a minimal setup for developing Shiny for Python applications.\nMounting the uv cache as a separate volume speeds up future re-creations of the devcontainer and installation of previously-installed dependencies.\n\n\n\n\n\n\n\n\n\n\nUltimately this wasn’t useful unless:\n\nwe have lots of projects depending on the same devcontainer spec, or\nwe went really custom with our CI and didn’t want to depend on pre-built github actions\n\n\n\n\n\nAdded a github action to build the devcontainer and publish it for the following purposes:\n\nTo make future devcontainer builds faster\n\nThis is really only useful if you have multiple repositories that share the same devcontainer base, or a complex setup.\nIn a single repository setup, this would cause the same build to happen twice, once for the common devcontainer, and once for the project specific devcontainer. It would be best to factor that out to something like tjpalanca/devcontainers instead.\n\nTo use the devcontainer for executing CI actions consistent with the local development experience\n\nAdds some overhead in pulling the devcontainer\nCreates some problems when the devcontainer and the application code are edited at the same time (one workflow has to finish before the other)\nMakes using pre-built github actions a little hit or miss, depending on how those pre-build github actions are built.\n\n\n\n    # BEFORE: Make sure to login to docker registry\n    - name: Pre-build dev container image\n      uses: devcontainers/ci@v0.3\n      with:\n        imageName: ghcr.io/tjpalanca/tjbots/devcontainer\n        cacheFrom: ghcr.io/tjpalanca/tjbots/devcontainer\n        push: always\n\nThere is a separate mechanism to pre-build Github Codespaces images.\n\n\n\n\nThese are to help with rapid development.\n{\n    \"key\": \"shift+cmd+enter\",\n    \"command\": \"shiny.python.runApp\",\n    \"when\": \"shellExecutionSupported && editorLangId == 'python'\"\n}\n\n\n\n\nI’m used to using a Makefile to describe the build and deployment actions I want to take, but there’s this new project called act that purports to replace this and have the github action as the source of truth for both local and CI deployment.\n\nI decided against this - it’s a lot of complexity.\n\n\n\n\n\n\n\n\nInitially, the auto-reload feature did not work well in the devcontainer setup either in VS Code or in Positron.\nWe needed to set remote.autoForwardPortsSource to process and disable the fallback by setting remote.autoForwardPortsFallback to 0, which creates a bunch of spurious ones but also surfaced the autoreload port.\n\nSetting remote.restoreForwardedPorts to false alleviated it by forgetting every time the devcontainer is started.\n\nIt still does not work well enough, we need to run the app twice, but at least it’s good.\n\n\n\n\n\nI would like quarto to format my markdown in addition to the code blocks.\nI couldn’t find a clean way to do this, unfortunately.",
    "crumbs": [
      "Home",
      "Notes",
      "Development",
      "Dev Container"
    ]
  },
  {
    "objectID": "notes/01-development/01-devcontainer.html#creating-the-dev-container",
    "href": "notes/01-development/01-devcontainer.html#creating-the-dev-container",
    "title": "Dev Container",
    "section": "",
    "text": "Used microsoft’s base dev container and some devcontainer features to enable python with uv, nodejs, and quarto. This creates a minimal setup for developing Shiny for Python applications.\nMounting the uv cache as a separate volume speeds up future re-creations of the devcontainer and installation of previously-installed dependencies.",
    "crumbs": [
      "Home",
      "Notes",
      "Development",
      "Dev Container"
    ]
  },
  {
    "objectID": "notes/01-development/01-devcontainer.html#pre-building-the-dev-container",
    "href": "notes/01-development/01-devcontainer.html#pre-building-the-dev-container",
    "title": "Dev Container",
    "section": "",
    "text": "Ultimately this wasn’t useful unless:\n\nwe have lots of projects depending on the same devcontainer spec, or\nwe went really custom with our CI and didn’t want to depend on pre-built github actions\n\n\n\n\n\nAdded a github action to build the devcontainer and publish it for the following purposes:\n\nTo make future devcontainer builds faster\n\nThis is really only useful if you have multiple repositories that share the same devcontainer base, or a complex setup.\nIn a single repository setup, this would cause the same build to happen twice, once for the common devcontainer, and once for the project specific devcontainer. It would be best to factor that out to something like tjpalanca/devcontainers instead.\n\nTo use the devcontainer for executing CI actions consistent with the local development experience\n\nAdds some overhead in pulling the devcontainer\nCreates some problems when the devcontainer and the application code are edited at the same time (one workflow has to finish before the other)\nMakes using pre-built github actions a little hit or miss, depending on how those pre-build github actions are built.\n\n\n\n    # BEFORE: Make sure to login to docker registry\n    - name: Pre-build dev container image\n      uses: devcontainers/ci@v0.3\n      with:\n        imageName: ghcr.io/tjpalanca/tjbots/devcontainer\n        cacheFrom: ghcr.io/tjpalanca/tjbots/devcontainer\n        push: always\n\nThere is a separate mechanism to pre-build Github Codespaces images.",
    "crumbs": [
      "Home",
      "Notes",
      "Development",
      "Dev Container"
    ]
  },
  {
    "objectID": "notes/01-development/01-devcontainer.html#keybindings",
    "href": "notes/01-development/01-devcontainer.html#keybindings",
    "title": "Dev Container",
    "section": "",
    "text": "These are to help with rapid development.\n{\n    \"key\": \"shift+cmd+enter\",\n    \"command\": \"shiny.python.runApp\",\n    \"when\": \"shellExecutionSupported && editorLangId == 'python'\"\n}",
    "crumbs": [
      "Home",
      "Notes",
      "Development",
      "Dev Container"
    ]
  },
  {
    "objectID": "notes/01-development/01-devcontainer.html#executing-actions",
    "href": "notes/01-development/01-devcontainer.html#executing-actions",
    "title": "Dev Container",
    "section": "",
    "text": "I’m used to using a Makefile to describe the build and deployment actions I want to take, but there’s this new project called act that purports to replace this and have the github action as the source of truth for both local and CI deployment.\n\nI decided against this - it’s a lot of complexity.",
    "crumbs": [
      "Home",
      "Notes",
      "Development",
      "Dev Container"
    ]
  },
  {
    "objectID": "notes/01-development/01-devcontainer.html#troubleshooting",
    "href": "notes/01-development/01-devcontainer.html#troubleshooting",
    "title": "Dev Container",
    "section": "",
    "text": "Initially, the auto-reload feature did not work well in the devcontainer setup either in VS Code or in Positron.\nWe needed to set remote.autoForwardPortsSource to process and disable the fallback by setting remote.autoForwardPortsFallback to 0, which creates a bunch of spurious ones but also surfaced the autoreload port.\n\nSetting remote.restoreForwardedPorts to false alleviated it by forgetting every time the devcontainer is started.\n\nIt still does not work well enough, we need to run the app twice, but at least it’s good.\n\n\n\n\n\nI would like quarto to format my markdown in addition to the code blocks.\nI couldn’t find a clean way to do this, unfortunately.",
    "crumbs": [
      "Home",
      "Notes",
      "Development",
      "Dev Container"
    ]
  },
  {
    "objectID": "scenarios/01-grocerybot.html",
    "href": "scenarios/01-grocerybot.html",
    "title": "GroceryBot",
    "section": "",
    "text": "Lots of time spent looking at different websites (FairPrice, Cold Storage, Foodpanda, etc.) to look for the same item at different prices (and different SKUs)\nSave time, and do so while chatting away with GroceryBot.",
    "crumbs": [
      "Home",
      "Scenarios",
      "GroceryBot"
    ]
  },
  {
    "objectID": "scenarios/01-grocerybot.html#motivation",
    "href": "scenarios/01-grocerybot.html#motivation",
    "title": "GroceryBot",
    "section": "",
    "text": "Lots of time spent looking at different websites (FairPrice, Cold Storage, Foodpanda, etc.) to look for the same item at different prices (and different SKUs)\nSave time, and do so while chatting away with GroceryBot.",
    "crumbs": [
      "Home",
      "Scenarios",
      "GroceryBot"
    ]
  },
  {
    "objectID": "scenarios/01-grocerybot.html#workflow",
    "href": "scenarios/01-grocerybot.html#workflow",
    "title": "GroceryBot",
    "section": "Workflow",
    "text": "Workflow\n\nSpecify the item, and ask any questions\nWhen you c",
    "crumbs": [
      "Home",
      "Scenarios",
      "GroceryBot"
    ]
  }
]